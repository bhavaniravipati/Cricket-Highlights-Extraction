{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(path,h,w):\n",
    "    \n",
    "    feature_advert_list = []\n",
    "\n",
    "\n",
    "    for img_path in os.listdir(path):\n",
    "        if(img_path != '.DS_Store'):\n",
    "            img = image.load_img(path+'/'+img_path, target_size=(h,w))\n",
    "            #img = image.load_img(path+'/'+img_path, target_size=(161,81))\n",
    "            #img = image.load_img(path+'/'+img_path, target_size=(360, 64))\n",
    "            img_data = image.img_to_array(img)\n",
    "            img_data = np.expand_dims(img_data, axis=0)\n",
    "            img_data = preprocess_input(img_data)\n",
    "\n",
    "            vgg16_feature = model.predict(img_data)\n",
    "            vgg16_feature_np = np.array(vgg16_feature)\n",
    "\n",
    "            feature_advert_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "     \n",
    "    return np.array(feature_advert_list)\n",
    "\n",
    "def extract_features_image(img_path,h,w):\n",
    "    \n",
    "    feature_list = []\n",
    "\n",
    "\n",
    "    #for img_path in os.listdir(path):\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(h,w))\n",
    "    #img = image.load_img(img_path, target_size=(161,81))\n",
    "    #img = image.load_img(img_path, target_size=(360, 64))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "\n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "\n",
    "    feature_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "     \n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bowler_action = '/Users/bhavanirishitharavipati/Desktop/Machine Learning/bowleraction'\n",
    "path_non_bowler = '/Users/bhavanirishitharavipati/Desktop/Machine Learning/Non_Bowler'\n",
    "\n",
    "h = 360\n",
    "w = 64\n",
    "\n",
    "features_list_bowler_action = extract_features(path_bowler_action,h,w)\n",
    "features_list_non_bowler = extract_features(path_non_bowler,h,w)\n",
    "\n",
    "labels_non_bowler = np.ones(len(features_list_non_bowler))\n",
    "labels_bowler_action = np.zeros(len(features_list_bowler_action))\n",
    "feat_bowler_action = np.column_stack((features_list_bowler_action,labels_bowler_action))\n",
    "feat_non_bowler = np.column_stack((features_list_non_bowler,labels_non_bowler))\n",
    "\n",
    "feat_x_y = np.concatenate((feat_bowler_action,feat_non_bowler),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1e-07, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#print(len(feat_x_y[0]))\n",
    "Y_data = feat_x_y[:,len(feat_x_y[0])-1]\n",
    "#print(Y_data)\n",
    "X_data = feat_x_y[:,0:len(feat_x_y[0])-1]\n",
    "# Y_data = feat_x_y[:,5120]\n",
    "# #print(Y_data)\n",
    "# X_data = feat_x_y[:,0:5120]\n",
    "\n",
    "#x_tr,x_ts,y_tr,y_ts = train_test_split(X_data, Y_data, test_size=0.2,random_state=10)\n",
    "clf = LinearSVC(C=0.0000001)\n",
    "clf.fit(X_data, Y_data)\n",
    "#print(len(x_tr),len(y_tr))\n",
    "# clf.fit(x_tr,y_tr)\n",
    "# predictions_tr = (clf.predict(x_ts))\n",
    "# scores = cross_val_score(clf, x_tr, y_tr, cv=10)\n",
    "# test_acc = accuracy_score(y_ts,predictions_tr)\n",
    "\n",
    "# print(\"Training Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# print(\"Test Accuracy: %0.4f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameCapture_bowler(path): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "  \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "  \n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "        \n",
    "        success, image = vidObj.read() \n",
    "  \n",
    "        # Saves the frames with frame-count \n",
    "        if(success):\n",
    "            cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/exp4/%d.jpg\" % count, image)\n",
    "            \n",
    "            feature = extract_features_image(\"/Users/bhavanirishitharavipati/Desktop/exp4/\"+str(count)+\".jpg\")\n",
    "            \n",
    "            if(clf.predict(feature) == 1):\n",
    "                os.remove(\"/Users/bhavanirishitharavipati/Desktop/exp4/\"+str(count)+\".jpg\")\n",
    "\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_replay = '/Users/bhavanirishitharavipati/Desktop/Machine Learning/Replay'\n",
    "path_non_replay = '/Users/bhavanirishitharavipati/Desktop/Machine Learning/Non_Replay'\n",
    "\n",
    "h = 161\n",
    "w = 81\n",
    "\n",
    "features_list_replay = extract_features(path_replay,h,w)\n",
    "features_list_non_replay = extract_features(path_non_replay,h,w)\n",
    "\n",
    "\n",
    "labels_non_replay = np.ones(len(features_list_non_replay))\n",
    "labels_replay = np.zeros(len(features_list_replay))\n",
    "feat_replay = np.column_stack((features_list_replay,labels_replay))\n",
    "feat_non_replay = np.column_stack((features_list_non_replay,labels_non_replay))\n",
    "\n",
    "feat_x_y_new = np.concatenate((feat_replay,feat_non_replay),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#print(len(feat_x_y[0]))\n",
    "Y_data = feat_x_y_new[:,5120]\n",
    "#print(Y_data)\n",
    "X_data = feat_x_y_new[:,0:5120]\n",
    "#print(len(feat_x_y[0]))\n",
    "#x_tr,x_ts,y_tr,y_ts = train_test_split(X_data, Y_data, test_size=0.2,random_state=10)\n",
    "clf2 = LinearSVC(C=10)\n",
    "clf2.fit(X_data, Y_data)\n",
    "# print(len(x_tr),len(y_tr))\n",
    "# clf.fit(x_tr,y_tr)\n",
    "# predictions_tr = (clf.predict(x_ts))\n",
    "# scores = cross_val_score(clf, x_tr, y_tr, cv=10)\n",
    "# test_acc = accuracy_score(y_ts,predictions_tr)\n",
    "\n",
    "# print(\"Training Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# print(\"Test Accuracy: %0.4f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def crop_img(img):\n",
    "    center_x, center_y = img.shape[1] / 2, img.shape[0] / 2\n",
    "    height = center_y*2\n",
    "    height_scaled = img.shape[0] * 0.80\n",
    "    width = center_x*2\n",
    "    width_scaled = img.shape[1] * 0.74\n",
    "    top_y, bottom_y = height_scaled , height \n",
    "    left_x, right_x = 0, width-width_scaled\n",
    "    img_cropped = img[int(top_y):int(bottom_y), int(left_x):int(right_x)]\n",
    "    return img_cropped\n",
    "    \n",
    "    \n",
    "def FrameCapture_replay(path): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "  \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    \n",
    "  \n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "       \n",
    "        success, image = vidObj.read() \n",
    "        \n",
    "        \n",
    "        # Saves the frames with frame-count \n",
    "        if(success):\n",
    "            cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/umpire_new_2/%d.jpg\" % count, image)\n",
    "            \n",
    "            im = cv2.imread(\"/Users/bhavanirishitharavipati/Desktop/umpire_new_2/\"+str(count)+\".jpg\")\n",
    "            img_cropped = crop_img(im)\n",
    "        \n",
    "            cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/Machine Learning/cropped_image/%d.jpg\" % count, img_cropped)\n",
    "            \n",
    "            feature = extract_features_image(\"/Users/bhavanirishitharavipati/Desktop/Machine Learning/cropped_image/\"+str(count)+\".jpg\")\n",
    "        \n",
    "            #print(\"hello\")\n",
    "            \n",
    "            if(clf.predict(feature) == 1):\n",
    "                    os.remove(\"/Users/bhavanirishitharavipati/Desktop/umpire_new_2/\"+str(count)+\".jpg\")\n",
    "            \n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_img(img):\n",
    "    center_x, center_y = img.shape[1] / 2, img.shape[0] / 2\n",
    "    height = center_y*2\n",
    "    height_scaled = img.shape[0] * 0.75\n",
    "    width = center_x*2\n",
    "    width_scaled = img.shape[1] * 0.74\n",
    "    top_y, bottom_y = height_scaled , height \n",
    "    left_x, right_x = 0, width-width_scaled\n",
    "    img_cropped = img[int(top_y):int(bottom_y), int(left_x):int(right_x)]\n",
    "    return img_cropped\n",
    "\n",
    "def FrameCapture_Combined(path, clf, clf2,var):\n",
    "    \n",
    "   \n",
    "    \n",
    "     # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "  \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    \n",
    "    found = 0\n",
    "        \n",
    "    replay = 0\n",
    "  \n",
    "    while success: \n",
    "  \n",
    "        # vidObj object calls read \n",
    "        success, image = vidObj.read() \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(image)\n",
    "        \n",
    "        if found and success:\n",
    "            \n",
    "            try:\n",
    "                cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+var+str(count)+\".jpg\", image)\n",
    "            \n",
    "                im = cv2.imread(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+var+str(count)+\".jpg\")\n",
    "                img_cropped = crop_img(im)\n",
    "        \n",
    "                cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/cropped_image/\"+var+str(count)+\".jpg\", img_cropped)\n",
    "            \n",
    "                feature = extract_features_image(\"/Users/bhavanirishitharavipati/Desktop/cropped_image/\"+var+str(count)+\".jpg\",161,81)\n",
    "                if(clf2.predict(feature) == 0):\n",
    "                    print(\"I am replay\", count)\n",
    "                    replay = 1\n",
    "                    break\n",
    "#                 else:\n",
    "#                     print(\"I am non-replay\")\n",
    "#                     os.remove(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+str(count)+\".jpg\")\n",
    "            except:\n",
    "                print(\"hi\")\n",
    "        if(success and found != 1):\n",
    "            \n",
    "            cv2.imwrite(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+var+str(count)+\".jpg\", image)\n",
    "            feature = extract_features_image(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+var+str(count)+\".jpg\", 360,64)\n",
    "            # check bowler action\n",
    "            if(clf.predict(feature) == 0):\n",
    "                print(\"I am bowler action\", count)\n",
    "                found = 1\n",
    "            else:\n",
    "                os.remove(\"/Users/bhavanirishitharavipati/Desktop/Final_Results/\"+var+str(count)+\".jpg\")\n",
    "                \n",
    "        count+=1\n",
    "        \n",
    "    if(not found or not replay):\n",
    "        \n",
    "        for f in os.listdir(\"/Users/bhavanirishitharavipati/Desktop/Final_Results\"):\n",
    "            if(f.startswith(var)):\n",
    "                os.remove(os.path.join(\"/Users/bhavanirishitharavipati/Desktop/Final_Results\",f))\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "def CombineVideo(path_list):\n",
    "#     clip1 = VideoFileClip(\"/home/dharshini/Documents/ML/code/1.mp4\")\n",
    "#     clip2 = VideoFileClip(\"/home/dharshini/Documents/ML/code/2.mp4\")\n",
    "\n",
    "    video = concatenate_videoclips(path_list, method='compose')\n",
    "#     final_clip = concatenate_videoclips(path_list)\n",
    "    video.write_videofile(\"/Users/bhavanirishitharavipati/Desktop/combined_file.mp4\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am bowler action 52\n",
      "I am replay 279\n",
      "1\n",
      "I am bowler action 617\n",
      "2\n",
      "I am bowler action 268\n",
      "I am replay 640\n",
      "3\n",
      "I am bowler action 634\n",
      "I am replay 958\n",
      "4\n",
      "5\n",
      "I am bowler action 24\n",
      "I am replay 157\n",
      "6\n",
      "I am bowler action 0\n",
      "I am replay 345\n",
      "7\n",
      "I am bowler action 268\n",
      "I am replay 598\n",
      "8\n",
      "I am bowler action 125\n",
      "I am replay 126\n",
      "9\n",
      "I am bowler action 635\n",
      "10\n",
      "I am bowler action 406\n",
      "I am replay 595\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/bhavanirishitharavipati/Desktop/clips\"\n",
    "count=1\n",
    "path_list = []\n",
    "\n",
    "file_name=['a','b','c','d','e','f','g','h','i','j','k']\n",
    "\n",
    "while(count<=11):\n",
    "    path_new=path+\"/\"+str(count)+\".mp4\"\n",
    "    FrameCapture_Combined(path_new, clf, clf2, file_name[count-1])\n",
    "\n",
    "    \n",
    "    print(count)\n",
    "#     if(found and replay):\n",
    "#     print(\"true\")    \n",
    "    count+=1\n",
    "\n",
    "\n",
    "\n",
    "#CombineVideo(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def combineFrames():\n",
    "    os.system(\"ffmpeg -r 25 -i /Users/bhavanirishitharavipati/Desktop/Final_Results/sample%d.jpg -vcodec mpeg4 -y /Users/bhavanirishitharavipati/Desktop/Final_Results/movie.mp4 \")\n",
    "\n",
    "combineFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
